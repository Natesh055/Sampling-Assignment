{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a6ce8f-a40c-4c37-9c3d-dc8dabbc2271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/t2x0g9fn6pvdzyxvktzq_tn80000gn/T/ipykernel_12687/1225697189.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampling_methods['Stratified'] = balanced_df.groupby('Class').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Method: Random | Model: LogReg | Accuracy: 0.50\n",
      "Sampling Method: Random | Model: DecTree | Accuracy: 1.00\n",
      "Sampling Method: Random | Model: RandForest | Accuracy: 0.50\n",
      "Sampling Method: Random | Model: XGBoost | Accuracy: 0.50\n",
      "Sampling Method: Random | Model: GradBoost | Accuracy: 0.50\n",
      "Sampling Method: Stratified | Model: LogReg | Accuracy: 0.50\n",
      "Sampling Method: Stratified | Model: DecTree | Accuracy: 0.50\n",
      "Sampling Method: Stratified | Model: RandForest | Accuracy: 0.50\n",
      "Sampling Method: Stratified | Model: XGBoost | Accuracy: 0.50\n",
      "Sampling Method: Stratified | Model: GradBoost | Accuracy: 0.50\n",
      "Sampling Method: Systematic | Model: LogReg | Accuracy: 1.00\n",
      "Sampling Method: Systematic | Model: DecTree | Accuracy: 1.00\n",
      "Sampling Method: Systematic | Model: RandForest | Accuracy: 1.00\n",
      "Sampling Method: Systematic | Model: XGBoost | Accuracy: 1.00\n",
      "Sampling Method: Systematic | Model: GradBoost | Accuracy: 1.00\n",
      "Sampling Method: Cluster | Model: LogReg | Accuracy: 0.93\n",
      "Sampling Method: Cluster | Model: DecTree | Accuracy: 0.96\n",
      "Sampling Method: Cluster | Model: RandForest | Accuracy: 0.98\n",
      "Sampling Method: Cluster | Model: XGBoost | Accuracy: 0.98\n",
      "Sampling Method: Cluster | Model: GradBoost | Accuracy: 0.99\n",
      "Sampling Method: Bootstrap | Model: LogReg | Accuracy: 1.00\n",
      "Sampling Method: Bootstrap | Model: DecTree | Accuracy: 0.50\n",
      "Sampling Method: Bootstrap | Model: RandForest | Accuracy: 0.50\n",
      "Sampling Method: Bootstrap | Model: XGBoost | Accuracy: 0.50\n",
      "Sampling Method: Bootstrap | Model: GradBoost | Accuracy: 0.50\n",
      "\n",
      "Best Sampling Technique and Model:\n",
      "Sampling Method: Random\n",
      "Model: DecTree\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "balanced_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns),\n",
    "                         pd.DataFrame(y_resampled, columns=['Class'])], axis=1)\n",
    "\n",
    "confidence_level = 0.95\n",
    "margin_of_error = 0.05\n",
    "p_hat = y_resampled.mean()\n",
    "z_score = 1.96\n",
    "\n",
    "random_sample_size = int((z_score * 2 * p_hat * (1 - p_hat)) / (margin_of_error * 2))\n",
    "\n",
    "strata_variance = balanced_df['Class'].value_counts(normalize=True).std()\n",
    "if strata_variance == 0:\n",
    "    strata_variance = 1\n",
    "stratified_sample_size = int((z_score * 2 * p_hat * (1 - p_hat)) / ((margin_of_error / strata_variance) * 2))\n",
    "\n",
    "num_clusters = 5\n",
    "cluster_sample_size = int((z_score * 2 * p_hat * (1 - p_hat)) / ((margin_of_error / num_clusters) * 2))\n",
    "\n",
    "sampling_methods = {}\n",
    "\n",
    "sampling_methods['Random'] = balanced_df.sample(n=random_sample_size, random_state=42)\n",
    "\n",
    "sampling_methods['Stratified'] = balanced_df.groupby('Class').apply(\n",
    "    lambda group: group.sample(\n",
    "        int(stratified_sample_size * len(group) / len(balanced_df)),\n",
    "        replace=True,\n",
    "        random_state=42\n",
    "    )\n",
    ").reset_index(drop=True)\n",
    "\n",
    "step_size = len(balanced_df) // random_sample_size\n",
    "sampling_methods['Systematic'] = balanced_df.iloc[::step_size, :].reset_index(drop=True)\n",
    "\n",
    "balanced_df['Cluster'] = pd.cut(balanced_df['Time'], bins=num_clusters, labels=False)\n",
    "sampled_clusters = balanced_df['Cluster'].sample(num_clusters // 2, random_state=42).unique()\n",
    "sampling_methods['Cluster'] = balanced_df[balanced_df['Cluster'].isin(sampled_clusters)].reset_index(drop=True)\n",
    "\n",
    "sampling_methods['Bootstrap'] = balanced_df.sample(n=random_sample_size, replace=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'LogReg': LogisticRegression(max_iter=1000),\n",
    "    'DecTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandForest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'GradBoost': GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "model_performance = {}\n",
    "for method, data_sample in sampling_methods.items():\n",
    "    X_sample = data_sample.drop(columns=['Class', 'Cluster'], errors='ignore')\n",
    "    y_sample = data_sample['Class']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        \n",
    "        if method not in model_performance:\n",
    "            model_performance[method] = {}\n",
    "        model_performance[method][model_name] = accuracy\n",
    "\n",
    "for method, scores in model_performance.items():\n",
    "    for model_name, score in scores.items():\n",
    "        print(f\"Sampling Method: {method} | Model: {model_name} | Accuracy: {score:.2f}\")\n",
    "\n",
    "# Identifying the best sampling method and model\n",
    "best_sampling_method = \"\"\n",
    "best_model_name = \"\"\n",
    "best_accuracy = 0\n",
    "\n",
    "for method, scores in model_performance.items():\n",
    "    for model_name, score in scores.items():\n",
    "        if score > best_accuracy:\n",
    "            best_accuracy, best_sampling_method, best_model_name = score, method, model_name\n",
    "\n",
    "print(\"\\nBest Sampling Technique and Model:\")\n",
    "print(f\"Sampling Method: {best_sampling_method}\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
